{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo o simulador quântico\n",
    "dev = qml.device(\"default.qubit\", wires=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para armazenar os ansatze\n",
    "ansatz_list = []\n",
    "\n",
    "# Gera 30 ansatz diferentes\n",
    "for i in range(30):\n",
    "    def ansatz(params, wires=[0, 1], ansatz_id=i):\n",
    "        # Aplica um ansatz diferente dependendo do ID\n",
    "        if ansatz_id == 0:\n",
    "            qml.RX(params[0], wires=wires[0]),\n",
    "            qml.RY(params[1], wires=wires[1]),\n",
    "            qml.CNOT(wires=wires)\n",
    "        elif ansatz_id == 1:\n",
    "            qml.RY(params[0], wires=wires[0]),  # RY no qubit medido (cria superposição paramétrica)\n",
    "            qml.RX(params[1], wires=wires[1]),  # RX no qubit auxiliar\n",
    "            qml.CNOT(wires=[wires[1], wires[0]]),  # Entrelaçamento controlado pelo qubit 1\n",
    "            qml.RZ(params[2], wires=wires[0])   # RZ para ajuste fino da fase\n",
    "        elif ansatz_id == 2:\n",
    "            qml.CRX(params[0], wires=wires),\n",
    "            qml.RY(params[1], wires=wires[1]),\n",
    "            qml.RX(params[2], wires=wires[0])\n",
    "        elif ansatz_id == 3:\n",
    "            qml.RY(params[0], wires=wires[0]),\n",
    "            qml.CRZ(params[1], wires=wires),\n",
    "            qml.Hadamard(wires=wires[1])\n",
    "        elif ansatz_id == 4:\n",
    "            qml.RX(params[0], wires=wires[0]),\n",
    "            qml.RY(params[1], wires=wires[1]),\n",
    "            qml.CNOT(wires=wires),\n",
    "            qml.RZ(params[2], wires=wires[0])\n",
    "        elif ansatz_id == 5:\n",
    "            qml.RY(params[0], wires=wires[0]),  # RY em q0 (garante superposição)\n",
    "            qml.RX(params[1], wires=wires[1]),  # RX em q1\n",
    "            qml.CNOT(wires=[wires[1], wires[0]]),  # Entrelaça q1 → q0 (controlado por q1)\n",
    "            qml.RZ(params[2], wires=wires[0])   # Fase em q0 (afeta a medição)\n",
    "        elif ansatz_id == 6:\n",
    "            qml.CRY(params[0], wires=wires),\n",
    "            qml.RZ(params[1], wires=wires[0]),  \n",
    "            qml.RY(params[2], wires=wires[1])  # Substitui o X fixo\n",
    "        elif ansatz_id == 7:\n",
    "            qml.RY(params[0], wires=wires[0]),  # Mudei RZ para RY\n",
    "            qml.CRX(params[1], wires=wires),\n",
    "            qml.RX(params[2], wires=wires[1])  # Troquei Hadamard por RX parametrizado\n",
    "        elif ansatz_id == 8:\n",
    "            qml.RY(params[0], wires=wires[0]),\n",
    "            qml.CZ(wires=wires),\n",
    "            qml.RX(params[1], wires=wires[1]),\n",
    "            qml.RZ(params[2], wires=wires[0])\n",
    "        elif ansatz_id == 9:\n",
    "            qml.CRZ(params[0], wires=wires),\n",
    "            qml.CNOT(wires=[wires[1], wires[0]]),\n",
    "            qml.RY(params[1], wires=wires[1])\n",
    "        elif ansatz_id == 10:\n",
    "            qml.Hadamard(wires=wires[0]),\n",
    "            qml.CRX(params[0], wires=wires),\n",
    "            qml.RY(params[1], wires=wires[1]),\n",
    "            qml.RZ(params[2], wires=wires[0])\n",
    "        elif ansatz_id == 11:\n",
    "            qml.X(wires=wires[0]),\n",
    "            qml.CRY(params[0], wires=wires),\n",
    "            qml.Z(wires=wires[1]),\n",
    "            qml.RX(params[1], wires=wires[0])\n",
    "        elif ansatz_id == 12:\n",
    "            qml.RZ(params[0], wires=wires[0]),\n",
    "            qml.CNOT(wires=wires),\n",
    "            qml.RX(params[1], wires=wires[1]),\n",
    "            qml.RY(params[2], wires=wires[0])\n",
    "        elif ansatz_id == 13:\n",
    "            qml.Hadamard(wires=wires[0]),\n",
    "            qml.CZ(wires=wires),\n",
    "            qml.RY(params[0], wires=wires[1]),\n",
    "            qml.RZ(params[1], wires=wires[0])\n",
    "        elif ansatz_id == 14:\n",
    "            qml.CRX(params[0], wires=wires),\n",
    "            qml.CNOT(wires=wires),\n",
    "            qml.RZ(params[1], wires=wires[0]),\n",
    "            qml.RX(params[2], wires=wires[1])\n",
    "        elif ansatz_id == 15:\n",
    "            qml.Y(wires=wires[0]),\n",
    "            qml.CRZ(params[0], wires=wires),\n",
    "            qml.Hadamard(wires=wires[1]),\n",
    "            qml.RY(params[1], wires=wires[0])\n",
    "        elif ansatz_id == 16:\n",
    "            qml.RY(params[0], wires=wires[0]),\n",
    "            qml.CRX(params[1], wires=wires),\n",
    "            qml.CNOT(wires=wires),\n",
    "            qml.RZ(params[2], wires=wires[1])\n",
    "        elif ansatz_id == 17:\n",
    "            qml.Hadamard(wires=wires[0]),\n",
    "            qml.CRY(params[0], wires=wires),\n",
    "            qml.RZ(params[1], wires=wires[1]),\n",
    "            qml.RX(params[2], wires=wires[0])\n",
    "        elif ansatz_id == 18:\n",
    "            qml.X(wires=wires[1]),\n",
    "            qml.CZ(wires=wires),\n",
    "            qml.RY(params[0], wires=wires[0]),\n",
    "            qml.RZ(params[1], wires=wires[1])\n",
    "        elif ansatz_id == 19:\n",
    "            qml.RZ(params[0], wires=wires[0]),\n",
    "            qml.CRY(params[1], wires=wires),\n",
    "            qml.Hadamard(wires=wires[1]),\n",
    "            qml.RX(params[2], wires=wires[0])\n",
    "        elif ansatz_id == 20:\n",
    "            qml.CNOT(wires=wires),\n",
    "            qml.CRZ(params[0], wires=wires),\n",
    "            qml.RX(params[1], wires=wires[0]),\n",
    "            qml.RY(params[2], wires=wires[1])\n",
    "        elif ansatz_id == 21:\n",
    "            qml.Hadamard(wires=wires[0]),\n",
    "            qml.CRX(params[0], wires=wires),\n",
    "            qml.CZ(wires=wires),\n",
    "            qml.RZ(params[1], wires=wires[1])\n",
    "        elif ansatz_id == 22:\n",
    "            qml.RY(params[0], wires=wires[0]),\n",
    "            qml.CNOT(wires=wires),\n",
    "            qml.CRZ(params[1], wires=wires),\n",
    "            qml.RX(params[2], wires=wires[1])\n",
    "        elif ansatz_id == 23:\n",
    "            qml.Z(wires=wires[0]),\n",
    "            qml.CRY(params[0], wires=wires),\n",
    "            qml.RX(params[1], wires=wires[1]),\n",
    "            qml.RZ(params[2], wires=wires[0])\n",
    "        elif ansatz_id == 24:\n",
    "            qml.Hadamard(wires=wires[0]),\n",
    "            qml.CRZ(params[0], wires=wires),\n",
    "            qml.RY(params[1], wires=wires[1]),\n",
    "            qml.RX(params[2], wires=wires[0])\n",
    "        elif ansatz_id == 25:\n",
    "            qml.RX(params[0], wires=wires[1]),  # Substitui o X fixo\n",
    "            qml.CNOT(wires=wires),\n",
    "            qml.CRX(params[1], wires=wires),\n",
    "            qml.RZ(params[2], wires=wires[0])\n",
    "        elif ansatz_id == 26:\n",
    "            qml.RZ(params[0], wires=wires[0]),\n",
    "            qml.CZ(wires=wires),\n",
    "            qml.Hadamard(wires=wires[1]),\n",
    "            qml.RY(params[1], wires=wires[0])\n",
    "        elif ansatz_id == 27:\n",
    "            qml.RY(params[0], wires=wires[0]),\n",
    "            qml.CRX(params[1], wires=wires),\n",
    "            qml.Z(wires=wires[1]),\n",
    "            qml.RX(params[2], wires=wires[0])\n",
    "        elif ansatz_id == 28:\n",
    "            qml.Hadamard(wires=wires[0]),\n",
    "            qml.CNOT(wires=wires),\n",
    "            qml.CRY(params[0], wires=wires),\n",
    "            qml.RZ(params[1], wires=wires[1])\n",
    "        elif ansatz_id == 29:\n",
    "            qml.RX(params[0], wires=wires[0]),\n",
    "            qml.CRZ(params[1], wires=wires),\n",
    "            qml.CNOT(wires=wires),\n",
    "            qml.RY(params[2], wires=wires[1])\n",
    "\n",
    "    ansatz_list.append(ansatz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function ansatz at 0x7a86eec119e0>\n"
     ]
    }
   ],
   "source": [
    "print(ansatz_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def generic_circuit(params, ansatz_id, x, amplitde_embedding=True):\n",
    "\n",
    "    \"\"\"Circuit genérico que aplica um ansatz específico.\"\"\"\n",
    "    if amplitde_embedding:\n",
    "        qml.AmplitudeEmbedding(x, wires=[0, 1], normalize=True, pad_with=0.0)\n",
    "    else:\n",
    "        qml.AngleEmbedding(x, wires=[0, 1], rotation=\"X\")\n",
    "\n",
    "    ansatz = ansatz_list[ansatz_id]\n",
    "    ansatz(params)\n",
    "    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ansätze com 2 parâmetros: 0, 3, 9, 11, 13, 15, 18, 21, 26, 28\n",
    "todos os outros possuem 3 parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para fazer a previsão\n",
    "def predict(params, x, ansatz_id, bias, amplitde_embedding=True):\n",
    "    \"\"\"Faz previsões com o circuito genérico.\"\"\"\n",
    "    predictions = np.array([generic_circuit(params=params, ansatz_id=ansatz_id, amplitde_embedding=amplitde_embedding, x=x) ])\n",
    "    predictions = np.mean(predictions)\n",
    "    return predictions + bias\n",
    "\n",
    "#função de custo MSE padrão\n",
    "def MSE(params, X, y, ansatz_id, bias, amplitde_embedding=True):\n",
    "    \"\"\"Função de custo para otimização.\"\"\"\n",
    "    predictions = np.array([predict(params=params, x=x, ansatz_id=ansatz_id, bias=bias, amplitde_embedding=amplitde_embedding) for x in X])\n",
    "    return np.mean((predictions - y) ** 2)  # MSE\n",
    "\n",
    "#função de custo BCE\n",
    "def BCE(params, X, y, ansatz_id, bias, amplitde_embedding=True):\n",
    "    \"\"\"Função de custo para otimização.\"\"\"\n",
    "    predictions = np.array([predict(params=params, x=x, ansatz_id=ansatz_id, bias=bias, amplitde_embedding=amplitde_embedding) for x in X])\n",
    "    predictions = np.clip(predictions, 1e-15, 1 - 1e-15)  # Previne log(0)\n",
    "\n",
    "    return -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))  # BCE\n",
    "\n",
    "# função para calcular a acurácia\n",
    "def accuracy(params, X, y, ansatz_id, bias, amplitde_embedding=True):\n",
    "    \"\"\"Calcula a acurácia do modelo.\"\"\"\n",
    "    predictions = np.array([predict(params=params, x=x, ansatz_id=ansatz_id, bias=bias, amplitde_embedding=amplitde_embedding) for x in X])\n",
    "    predictions = np.sign(predictions)  # Converte para -1 ou 1\n",
    "    return np.mean(predictions == y)  # Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo os datasets\n",
    "df1 = pd.read_csv(\"./../datasets/blobs_datasets/blobs_2classes_2features_50samples_high_noise.csv\")\n",
    "df1.nome = \"blobs_2classes_2features_50samples_high_noise\"\n",
    "df2 = pd.read_csv(\"./../datasets/blobs_datasets/blobs_2classes_2features_50samples_low_noise.csv\")\n",
    "df2.nome = \"blobs_2classes_2features_50samples_low_noise\"\n",
    "df3 = pd.read_csv(\"./../datasets/blobs_datasets/blobs_2classes_2features_50samples_no_noise.csv\")\n",
    "df3.nome = \"blobs_2classes_2features_50samples_no_noise\"\n",
    "df4 = pd.read_csv(\"./../datasets/blobs_datasets/blobs_2classes_2features_500samples_high_noise.csv\")\n",
    "df4.nome = \"blobs_2classes_2features_500samples_high_noise\"\n",
    "df5 = pd.read_csv(\"./../datasets/blobs_datasets/blobs_2classes_2features_500samples_low_noise.csv\")\n",
    "df5.nome = \"blobs_2classes_2features_500samples_low_noise\"\n",
    "df6 = pd.read_csv(\"./../datasets/blobs_datasets/blobs_2classes_2features_500samples_no_noise.csv\")\n",
    "df6.nome = \"blobs_2classes_2features_500samples_no_noise\"\n",
    "df7 = pd.read_csv(\"./../datasets/circles_datasets/circles_50samples_high_noise.csv\")\n",
    "df7.nome = \"circles_50samples_high_noise\"\n",
    "df8 = pd.read_csv(\"./../datasets/circles_datasets/circles_50samples_low_noise.csv\")\n",
    "df8.nome = \"circles_50samples_low_noise\"\n",
    "df9 = pd.read_csv(\"./../datasets/circles_datasets/circles_50samples_no_noise.csv\")\n",
    "df9.nome = \"circles_50samples_no_noise\"\n",
    "df10 = pd.read_csv(\"./../datasets/circles_datasets/circles_500samples_high_noise.csv\")\n",
    "df10.nome = \"circles_500samples_high_noise\"\n",
    "df11 = pd.read_csv(\"./../datasets/circles_datasets/circles_500samples_low_noise.csv\")\n",
    "df11.nome = \"circles_500samples_low_noise\"\n",
    "df12 = pd.read_csv(\"./../datasets/circles_datasets/circles_500samples_no_noise.csv\")\n",
    "df12.nome = \"circles_500samples_no_noise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando os samples dos dataframes\n",
    "\n",
    "with open(\"./../datasets/blobs_metrics/blobs_2classes_2features_50samples_high_noise.pkl\", 'rb') as file:\n",
    "    metrics1 = pickle.load(file)\n",
    "\n",
    "with open(\"./../datasets/blobs_metrics/blobs_2classes_2features_50samples_low_noise.pkl\", 'rb') as file:\n",
    "    metrics2 = pickle.load(file)\n",
    "\n",
    "with open(\"./../datasets/blobs_metrics/blobs_2classes_2features_50samples_no_noise.pkl\", 'rb') as file:\n",
    "    metrics3 = pickle.load(file)\n",
    "\n",
    "with open(\"./../datasets/blobs_metrics/blobs_2classes_2features_500samples_high_noise.pkl\", 'rb') as file:\n",
    "    metrics4 = pickle.load(file)\n",
    "\n",
    "with open(\"./../datasets/blobs_metrics/blobs_2classes_2features_500samples_low_noise.pkl\", 'rb') as file:\n",
    "    metrics5 = pickle.load(file)\n",
    "\n",
    "with open(\"./../datasets/blobs_metrics/blobs_2classes_2features_500samples_no_noise.pkl\", 'rb') as file:\n",
    "    metrics6 = pickle.load(file)\n",
    "\n",
    "with open(\"./../datasets/circles_metrics/circles_50samples_high_noise.pkl\", 'rb') as file:\n",
    "    metrics7 = pickle.load(file)\n",
    "\n",
    "with open(\"./../datasets/circles_metrics/circles_50samples_low_noise.pkl\", 'rb') as file:\n",
    "    metrics8 = pickle.load(file)\n",
    "\n",
    "with open(\"./../datasets/circles_metrics/circles_50samples_no_noise.pkl\", 'rb') as file:\n",
    "    metrics9 = pickle.load(file)\n",
    "\n",
    "with open(\"./../datasets/circles_metrics/circles_500samples_high_noise.pkl\", 'rb') as file:\n",
    "    metrics10 = pickle.load(file)\n",
    "\n",
    "with open(\"./../datasets/circles_metrics/circles_500samples_low_noise.pkl\", 'rb') as file:\n",
    "    metrics11 = pickle.load(file)\n",
    "\n",
    "with open(\"./../datasets/circles_metrics/circles_500samples_no_noise.pkl\", 'rb') as file:\n",
    "    metrics12 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settando variáveis para geração de dados\n",
    "\n",
    "samples = [\n",
    "    metrics1, metrics2, metrics3,\n",
    "    metrics4, metrics5, metrics6,\n",
    "    metrics7, metrics8, metrics9,\n",
    "    metrics10, metrics11, metrics12\n",
    "]\n",
    "\n",
    "data_frames = [\n",
    "    df1, df2, df3, df4, df5, df6,\n",
    "    df7, df8, df9, df10, df11, df12\n",
    "]\n",
    "\n",
    "cost_functions = [MSE]\n",
    "\n",
    "optimizers = [qml.AdamOptimizer(stepsize=0.1)]\n",
    "\n",
    "ansatz_ids = list(range(30))\n",
    "\n",
    "samples_ids = list(range(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_dataframe(df_novo, arquivo):\n",
    "    if os.path.exists(arquivo):\n",
    "        df_existente = pd.read_csv(arquivo)\n",
    "        df_final = pd.concat([df_existente, df_novo], ignore_index=True)\n",
    "    else:\n",
    "        df_final = df_novo\n",
    "    \n",
    "    df_final.to_csv(arquivo, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrng_weights = np.random.default_rng(42)\\n\\nfor ansatz_id in ansatz_ids:\\n    for (sample, df) in (zip(samples, data_frames)):\\n        for sample_id in samples_ids:\\n            for cost_function in (cost_functions):\\n                for  opt in (optimizers):\\n                    for amplitde_embedding in ([True]):\\n\\n                        # resetando o optimizador\\n                        if opt.__class__.__name__ == \"GradientDescentOptimizer\":\\n                            opt = qml.GradientDescentOptimizer(stepsize=0.1)\\n                        elif opt.__class__.__name__ == \"AdamOptimizer\":\\n                            opt = qml.AdamOptimizer(stepsize=0.1)\\n\\n                        # Definindo os parâmetros atualizaveis pelo otimizador\\n                        num_params = 3 if ansatz_id not in [0, 3, 9, 11, 13, 15, 18, 21, 26, 28] else 2\\n                        params = np.array(2 * rng_weights.random(num_params) * np.pi, requires_grad=True)\\n                        bias = np.array(0.0, requires_grad=True)\\n\\n                        # Definindo o número de iterações\\n                        epoch = 20\\n\\n                        # separando o dataset em treino e teste\\n                        X_train = df.loc[sample[\"samples\"][sample_id], df.columns != \"target\"]\\n                        X_train = X_train.to_numpy()\\n                        y_train = df.loc[sample[\"samples\"][sample_id], \"target\"]\\n                        y_train = y_train.values.flatten()\\n                        X_test = df.loc[~df.index.isin(sample[\"samples\"][sample_id]), df.columns != \"target\"]\\n                        X_test = X_test.to_numpy()\\n                        y_test = df.loc[~df.index.isin(sample[\"samples\"][sample_id]), \"target\"]\\n                        y_test = y_test.values.flatten()\\n\\n                        #ajustando o target y para o valor correspondente a saída do circuito [-1, 1], classe 0 = -1 e classe 1 = 1\\n                        y_train = 2*y_train - 1\\n                        y_test = 2*y_test - 1\\n\\n                        # Treinamento do modelo\\n                        for i in tqdm(range(epoch), desc=f\"Samples id: {sample_id}, Treinando o modelo\", unit=\"epoch\"):\\n\\n                            params,_,_,_,bias = opt.step(cost_function, params, X_train, y_train, ansatz_id, bias, amplitde_embedding=amplitde_embedding)\\n\\n                            if i == epoch - 1:\\n                                # Avaliando a acurácia no final do treinamento\\n                                accuracy_train = accuracy(params, X_train, y_train, ansatz_id, bias, amplitde_embedding=amplitde_embedding)\\n                                print(f\"Epoch {i+1}/{epoch}, Acurácia de Treinamento: {accuracy_train:.4f}\")\\n\\n                        # Avaliando a acurácia no conjunto de teste\\n                        accuracy_test = accuracy(params, X_test, y_test, ansatz_id, bias, amplitde_embedding=amplitde_embedding)\\n                        print(f\"Acurácia de Teste: {accuracy_test:.4f}\")\\n\\n\\n                        # Salvando os resultados em um dicionário\\n                        results = {\\n                            \"TIPO_DE_CARREGAMENTO_ENTRADA\": amplitde_embedding,\\n                            \"ARQUITETURA_ANSATZ\": ansatz_id,\\n                            \"OTIMIZADOR\": opt.__class__.__name__,\\n                            \"BASE_DE_DADOS\": df.nome,\\n                            \"SAMPLE\": sample_id,\\n                            \"METRICA_NAO_SUPERVISIONADA\": cost_function.__name__,\\n                            \"INDICE_DIVISAO_BASE_DE_DADOS\": 0.7,\\n                            \"ACURACIA_TREINAMENTO\": accuracy_train,\\n                            \"ACURACIA_TESTE\": accuracy_test\\n                        }\\n\\n                        # Salvando os resultados em um csv\\n                        salvar_dataframe(pd.DataFrame([results]), \"./../ansatz_result/resultados.csv\")\\n\\n'"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#treinamento, teste e geração de dados\n",
    "\"\"\"\n",
    "rng_weights = np.random.default_rng(42)\n",
    "\n",
    "for ansatz_id in ansatz_ids:\n",
    "    for (sample, df) in (zip(samples, data_frames)):\n",
    "        for sample_id in samples_ids:\n",
    "            for cost_function in (cost_functions):\n",
    "                for  opt in (optimizers):\n",
    "                    for amplitde_embedding in ([True]):\n",
    "\n",
    "                        # resetando o optimizador\n",
    "                        if opt.__class__.__name__ == \"GradientDescentOptimizer\":\n",
    "                            opt = qml.GradientDescentOptimizer(stepsize=0.1)\n",
    "                        elif opt.__class__.__name__ == \"AdamOptimizer\":\n",
    "                            opt = qml.AdamOptimizer(stepsize=0.1)\n",
    "                        \n",
    "                        # Definindo os parâmetros atualizaveis pelo otimizador\n",
    "                        num_params = 3 if ansatz_id not in [0, 3, 9, 11, 13, 15, 18, 21, 26, 28] else 2\n",
    "                        params = np.array(2 * rng_weights.random(num_params) * np.pi, requires_grad=True)\n",
    "                        bias = np.array(0.0, requires_grad=True)\n",
    "\n",
    "                        # Definindo o número de iterações\n",
    "                        epoch = 20\n",
    "\n",
    "                        # separando o dataset em treino e teste\n",
    "                        X_train = df.loc[sample[\"samples\"][sample_id], df.columns != \"target\"]\n",
    "                        X_train = X_train.to_numpy()\n",
    "                        y_train = df.loc[sample[\"samples\"][sample_id], \"target\"]\n",
    "                        y_train = y_train.values.flatten()\n",
    "                        X_test = df.loc[~df.index.isin(sample[\"samples\"][sample_id]), df.columns != \"target\"]\n",
    "                        X_test = X_test.to_numpy()\n",
    "                        y_test = df.loc[~df.index.isin(sample[\"samples\"][sample_id]), \"target\"]\n",
    "                        y_test = y_test.values.flatten()\n",
    "\n",
    "                        #ajustando o target y para o valor correspondente a saída do circuito [-1, 1], classe 0 = -1 e classe 1 = 1\n",
    "                        y_train = 2*y_train - 1\n",
    "                        y_test = 2*y_test - 1\n",
    "\n",
    "                        # Treinamento do modelo\n",
    "                        for i in tqdm(range(epoch), desc=f\"Samples id: {sample_id}, Treinando o modelo\", unit=\"epoch\"):\n",
    "\n",
    "                            params,_,_,_,bias = opt.step(cost_function, params, X_train, y_train, ansatz_id, bias, amplitde_embedding=amplitde_embedding)\n",
    "                            \n",
    "                            if i == epoch - 1:\n",
    "                                # Avaliando a acurácia no final do treinamento\n",
    "                                accuracy_train = accuracy(params, X_train, y_train, ansatz_id, bias, amplitde_embedding=amplitde_embedding)\n",
    "                                print(f\"Epoch {i+1}/{epoch}, Acurácia de Treinamento: {accuracy_train:.4f}\")\n",
    "\n",
    "                        # Avaliando a acurácia no conjunto de teste\n",
    "                        accuracy_test = accuracy(params, X_test, y_test, ansatz_id, bias, amplitde_embedding=amplitde_embedding)\n",
    "                        print(f\"Acurácia de Teste: {accuracy_test:.4f}\")\n",
    "\n",
    "\n",
    "                        # Salvando os resultados em um dicionário\n",
    "                        results = {\n",
    "                            \"TIPO_DE_CARREGAMENTO_ENTRADA\": amplitde_embedding,\n",
    "                            \"ARQUITETURA_ANSATZ\": ansatz_id,\n",
    "                            \"OTIMIZADOR\": opt.__class__.__name__,\n",
    "                            \"BASE_DE_DADOS\": df.nome,\n",
    "                            \"SAMPLE\": sample_id,\n",
    "                            \"METRICA_NAO_SUPERVISIONADA\": cost_function.__name__,\n",
    "                            \"INDICE_DIVISAO_BASE_DE_DADOS\": 0.7,\n",
    "                            \"ACURACIA_TREINAMENTO\": accuracy_train,\n",
    "                            \"ACURACIA_TESTE\": accuracy_test\n",
    "                        }\n",
    "\n",
    "                        # Salvando os resultados em um csv\n",
    "                        salvar_dataframe(pd.DataFrame([results]), \"./../ansatz_result/resultados.csv\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wrapper(args):\n",
    "    \"\"\"Função que encapsula toda a lógica de treinamento para paralelização\"\"\"\n",
    "    (ansatz_id, sample, df, sample_id, cost_function, opt_class, \n",
    "     amplitde_embedding, rng_weights, nome,save_path) = args\n",
    "    \n",
    "    # Reset do otimizador\n",
    "    if opt_class.__class__.__name__ == \"GradientDescentOptimizer\":\n",
    "        opt = qml.GradientDescentOptimizer(stepsize=0.1)\n",
    "    elif opt_class.__class__.__name__ == \"AdamOptimizer\":\n",
    "        opt = qml.AdamOptimizer(stepsize=0.1)\n",
    "    else:\n",
    "        opt = opt_class(stepsize=0.1)\n",
    "    \n",
    "    # Configuração dos parâmetros\n",
    "    num_params = 3 if ansatz_id not in [0, 3, 9, 11, 13, 15, 18, 21, 26, 28] else 2\n",
    "    params = np.array(2 * rng_weights.random(num_params) * np.pi, requires_grad=True)\n",
    "    bias = np.array(0.0, requires_grad=True)\n",
    "\n",
    "    # Preparação dos dados\n",
    "    X_train = df.loc[sample[\"samples\"][sample_id], df.columns != \"target\"].to_numpy()\n",
    "    y_train = 2*df.loc[sample[\"samples\"][sample_id], \"target\"].values.flatten() - 1\n",
    "    \n",
    "    X_test = df.loc[~df.index.isin(sample[\"samples\"][sample_id]), df.columns != \"target\"].to_numpy()\n",
    "    y_test = 2*df.loc[~df.index.isin(sample[\"samples\"][sample_id]), \"target\"].values.flatten() - 1\n",
    "\n",
    "    # Treinamento\n",
    "    epoch = 20\n",
    "    for i in range(epoch):\n",
    "        params,_,_,_,bias = opt.step(cost_function, params, X_train, y_train, ansatz_id, bias, \n",
    "                               amplitde_embedding=amplitde_embedding)\n",
    "    \n",
    "    # Avaliação\n",
    "    accuracy_train = accuracy(params, X_train, y_train, ansatz_id, bias, \n",
    "                             amplitde_embedding=amplitde_embedding)\n",
    "    accuracy_test = accuracy(params, X_test, y_test, ansatz_id, bias, \n",
    "                            amplitde_embedding=amplitde_embedding)\n",
    "\n",
    "    # Retorna resultados para coleta\n",
    "    return {\n",
    "        \"TIPO_DE_CARREGAMENTO_ENTRADA\": amplitde_embedding,\n",
    "        \"ARQUITETURA_ANSATZ\": ansatz_id,\n",
    "        \"OTIMIZADOR\": opt.__class__.__name__,\n",
    "        \"BASE_DE_DADOS\": nome,\n",
    "        \"SAMPLE\": sample_id,\n",
    "        \"METRICA_NAO_SUPERVISIONADA\": cost_function.__name__,\n",
    "        \"INDICE_DIVISAO_BASE_DE_DADOS\": 0.7,\n",
    "        \"ACURACIA_TREINAMENTO\": accuracy_train,\n",
    "        \"ACURACIA_TESTE\": accuracy_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração de paralelização\n",
    "def parallel_training(ansatz_ids, samples, data_frames, samples_ids, \n",
    "                     cost_functions, optimizers, save_path, max_workers=None):\n",
    "    \n",
    "    rng_weights = np.random.default_rng(42)\n",
    "    tasks = []\n",
    "    \n",
    "    # Gerar todas as combinações de parâmetros\n",
    "    for ansatz_id in ansatz_ids:\n",
    "        for sample, df in zip(samples, data_frames):\n",
    "            for sample_id in samples_ids:\n",
    "                for cost_function in cost_functions:\n",
    "                    for opt_class in optimizers:\n",
    "                        for amplitde_embedding in [True]:\n",
    "                            tasks.append((\n",
    "                                ansatz_id, sample, df, sample_id, \n",
    "                                cost_function, opt_class, amplitde_embedding, \n",
    "                                rng_weights, df.nome, save_path\n",
    "                            ))\n",
    "\n",
    "    # Execução paralela\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(tqdm(executor.map(train_wrapper, tasks), \n",
    "                      total=len(tasks), \n",
    "                      desc=\"Executando Experimentos\"))\n",
    "    \n",
    "    # Salvar resultados\n",
    "    final_df = pd.DataFrame(results)\n",
    "    salvar_dataframe(final_df, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executando Experimentos: 100%|██████████| 10800/10800 [16:25:37<00:00,  5.48s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Uso\n",
    "parallel_training(\n",
    "\n",
    "    ansatz_ids = list(range(30)),\n",
    "\n",
    "    samples = [\n",
    "    metrics1, metrics2, metrics3,\n",
    "    metrics4, metrics5, metrics6,\n",
    "    metrics7, metrics8, metrics9,\n",
    "    metrics10, metrics11, metrics12\n",
    "    ],\n",
    "\n",
    "    data_frames = [\n",
    "        df1, df2, df3, df4, df5, df6,\n",
    "        df7, df8, df9, df10, df11, df12\n",
    "    ],\n",
    "\n",
    "    samples_ids = list(range(30)),\n",
    "\n",
    "    cost_functions = [MSE],\n",
    "\n",
    "    optimizers = [qml.AdamOptimizer(stepsize=0.1)],\n",
    "\n",
    "    save_path = \"./../ansatz_result/resultados.csv\",\n",
    "\n",
    "    max_workers = 12 \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pennylane_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
