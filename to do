Tarefas para fazer sobre o pibic

- Preparar um código que receba uma tabela de resultados de acurácia de diferentes arquiteturas em diferentes bases de dados. 
    (checar a tabela da última tarefa de Samuell)
- Treinar algoritmos inteligentes clássicos (usar todos os mesmos modelos de IA utilizados na tabela 2 do artigo[1] 
    (SVM, MLP, ..., com todos os parâmetros variados que estão lá), para, dadas as medidas de complexidade de bases de dados como entrada, 
    o modelo de IA consiga prever a acurácia para cada um dos ansatz (problema de regressão). 
- Treinar algoritmos inteligentes clássicos (usar todos os mesmos modelos de IA utilizados na tabela 2 do artigo[1] 
    (SVM, MLP, ..., com todos os parâmetros variados que estão lá), para, dadas as medidas de complexidade de bases de dados como entrada, 
    o modelo de IA consiga prever o melhor ansatz (problema de classificação). Para esta modelagem, você vai precisar considerar que a coluna 
    Target não a acurácia, e sim o número da melhor configuração de CQV. Você pode dividir os CQVs por modalidade de carregamento de entrada 
    (amplitude encoding e phase encoding) e analisar em experimentos separados os 2 cenários de carregamento.

Para testar o código, criar uma tabela fictícia. Em breve, Samuell irá fornecer essa tabela real.
Você deve testar usando: todas as medidas de complexidade; uma medida de cada vez; testar se há um algoritmo de verifique qual a 
melhor combinação de medidas de complexidade para esta tarefa (buscar na literatura, sklearn, etc).

- simular 30 circutios diferentes com pennylane, serão circuitos simples, 2 qubits e gerar resultados para teste e checagem da minha , estarão na pasta ansatz
- definir um padrão para o armazenamento da estrutura do ansatz
- os dados que serão recebidos serão colunas contendo as métricas de complexidade dos dados usados para treinar os ansatz 
- aplicar normalização nas variáveis numéricas
- fazer o treinamento desses ansatz para as bases de dados criadas sinteticamente na atividade anterior
    vai ser usado as mesmas tabelas geradas, e as divisões feitas anteriormente no padrão 70/30 armazenadas no arquivo .pkl
- armazenar o resultado desses treinamentos em uma tabela no padrão citado anteriormente
- criar modelos:
    DT Decision Tree Classifier
    DTR Decision Tree Regressor
    MLP(R)-500 Multi-layer Perceptron classifier (or regressor), Hidden layer=500.
    MLP(R)-100-100-100 Multi-layer Perceptron classifier (or regressor), Hidden layers=100,100,100.
    MLP(R)-500-500-500 Multi-layer Perceptron classifier (or regressor), Hidden layers=500,500,500.
    SVM Linear Support Vector Classification.
    SVM-RBF C-Support Vector Classification, C=1.0, Kernel=RBF, Gamma=Scale.
    SVR-RBF Epsilon-Support Vector Regression, C=1.0, Kernel=RBF, Gamma=Scale.
    SVM-Sigmoid C-Support Vector Classification, C=1.0, Kernel=Sigmoid, Gamma=Scale.
    SVR-Sigmoid Epsilon-Support Vector Regression, C=1.0, Kernel=Sigmoid, Gamma=Scale.
    SVM-Linear C-Support Vector Classification, C=1.0, Kernel=Linear, Gamma=scale.
    SVR-Linear Epsilon-Support Vector Regression, C=1.0, Kernel=Linear, Gamma=Scale.
    NaiveBayes Gaussian Naive Bayes algorithm for classification.
    kNN Classifier implementing the k-nearest neighbors vote, k=5.
    kNNR Regression based on k-nearest neighbors, k=5.
    NearestCentroid Nearest centroid classifier, metric=euclidean.
    LogisticRegression Logistic Regression classifier.
    RF Random forest classifier, n estimators=10.
    Ensemble-AB AdaBoost classifier, estimator=DecisionTreeClassifier, n estimators=50.
    Ensemble-Bg Bagging classifier, estimator=DecisionTreeClassifier, n estimators=10.
    Ensemble-GB Gradient Boosting for classification.
    Adaboost AdaBoost regressor, estimator = DecisionTreeRegressor, n estimators=50.
    Bagging Bagging classifier. estimator=DecisionTreeClassifier, n estimartors=10.
    Linear Regression Ordinary least squares Linear Regression.

-adicionar possíveis modelos bem conhecidos e que tenham um bom poder de classificação
-biblioteclas para utilizar nos modelos, possívelmente pytorhc como prioridade, como secundárias scikit-learn e talvez tensorflow
-criar os modelos de regressão e classificação, estarão armazenados na pasta models
-para classificação retornar o melhor ansatz que foi previsto, e também retornar os 3 melhores ansatz
-para regressão retornar a acurácia prevista
-validar os resultados previstos e a eficiência dos modelos

